{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4057f9-6ba1-42a0-b11f-33f6d655b4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3650ff87-a34e-42ef-b704-9bc08ac3535f",
   "metadata": {},
   "outputs": [],
   "source": [
    "--->  Web scraping is an automatic method to obtain large amounts of data from websites.\n",
    "      Most of this data is unstructured data in an HTML format which is then converted into structured data in a spreadsheet or a database so that it can be used in various applications.\n",
    "    \n",
    "    Web scraping is used to automate the process of data collection, which can be cumbersome and time-consuming if done manually. \n",
    "    \n",
    "    Three areas where webscrapping are commonly used are as folows:\n",
    "        E-commerce\n",
    "        Research\n",
    "        Finance\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac155062-bd1c-4cf5-857c-6af736023a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a1039d-ae8f-4900-b5d1-3ac9d98e3538",
   "metadata": {},
   "outputs": [],
   "source": [
    "Manual Scraping\n",
    "HTML Parsing\n",
    "Web Api\n",
    "Headless Browsers\n",
    "Machine Learning\n",
    "Proxy Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78767fc5-ea6e-4c0c-97cf-fbab0f8e7715",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5780f865-5aa8-4951-9b7c-ed575bf13454",
   "metadata": {},
   "outputs": [],
   "source": [
    "Beautiful Soup provides simple methods for navigating, searching, and modifying a parse tree in HTML, XML files.\n",
    "It transforms a complex HTML document into a tree of Python objects.\n",
    "It also automatically converts the document to Unicode, so you don't have to think about encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb6ddd8-be36-4389-906b-5d816b630c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9835fa8d-100f-48c4-b9e9-2892124f393e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Flask is a lightweight framework to build websites.\n",
    "We'll use this to parse our collected data and display it as HTML in a new HTML file.\n",
    "The requests module allows us to send http requests to the website we want to scrape.\n",
    "The first line imports the Flask class and the render_template method from the flask library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e2e6b2-4a55-493f-b895-1dc087fec4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Write the names of AWS services used in this project. Also, explain the use of each service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41733f25-925b-47be-9618-a520791a2502",
   "metadata": {},
   "outputs": [],
   "source": [
    "Amazon EC2: Amazon Elastic Compute Cloud (EC2) is a web service that provides scalable computing resources in the cloud. It can be used to launch virtual machines (instances) and run web scraping software, enabling faster processing of data and allowing developers to easily scale up or down their computing resources as needed.\n",
    "\n",
    "Amazon S3: Amazon Simple Storage Service (S3) is a cloud-based object storage service that provides developers with secure, durable, and scalable storage for their web scraping data. It can be used to store the raw data collected during web scraping, as well as the output data generated from data processing.\n",
    "\n",
    "AWS Lambda: AWS Lambda is a serverless computing service that allows developers to run code without provisioning or managing servers. It can be used to create serverless web scrapers that can automatically execute at scheduled intervals or in response to specific events, such as a user input or a change in a website.\n",
    "\n",
    "Amazon RDS: Amazon Relational Database Service (RDS) is a managed database service that makes it easy to set up, operate, and scale a relational database in the cloud. It can be used to store and manage the structured data generated from web scraping, such as metadata, user information, or scraped content.\n",
    "\n",
    "Amazon CloudWatch: Amazon CloudWatch is a monitoring service that provides developers with real-time monitoring and visibility into their AWS resources, applications, and services. It can be used to monitor the performance and availability of the web scraping software and trigger alerts or notifications in case of failures or errors.\n",
    "\n",
    "Amazon SQS: Amazon Simple Queue Service (SQS) is a fully managed message queuing service that enables reliable and scalable communication between distributed software components. It can be used to manage the flow of data between different components of a web scraping project, such as the web scraper, the data processor, and the database.\n",
    "\n",
    "Overall, AWS provides a range of services that can be used to build scalable, reliable, and efficient web scraping projects in the cloud. The specific AWS services used in a project will depend on the specific requirements and constraints of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e9f508-7066-479a-8ce7-a22dabe6262d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
